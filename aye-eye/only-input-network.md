# only-input-network

### 2024-11-21 18:20 - only input

as I was walking home, -- wait, lemme back up a moment. the last few days I've been fascinated by AI a bit, because I watched [a really great video](https://www.youtube.com/watch?v=9-Jl0dxWQs8) about how language models store a lot of information. I started to think about how that style of thinking (n-dimensional space can encode different attributes in dimensions nearly orthagonal to eachother) could be used to compress a whole lot of data, because imagine what I want to do is to take in a whole lot of songs (imagine I have my music collection of songs that I like), and so what I do is the same thing: I have the model predict the frequential output of the song, training it with the song data -- then, when I go to play the song back, I now have an array of different outputs to the song -- so, the song itself can even come out slightly differently. inotherwords, it lossly encodes (like an mp3) the song data, where the output isn't a perfect reproduction of the original. a file like an mp3 has one input and one output -- and the output is compressed because it takes a lot of the frequencies and simplifying them -- which those simplified frequencies can then be stored in less space. however, in the case of me training the AI with my music collection, is that it's not just one song, but thousands -- or what if I trained it with millions of songs -- and inevitably there will be songs with similar frequency patterns -- which those different attributes will be then stored (like facts) in the n-dimensional space as being differences in direction/magnitude of the vectors associated with the the frequencies. thing is, I wasn't really sure how to tokenise the song frequencies (it's obvious to me now though) and there's no way that I have the computing resources to train up an AI with the spotify catalogue -- so I didn't really consider the idea much further. it's a cool idea for people with a lot of computing resources and stuff.
the other idea I was thinking about was a way to take in input and somehow convert those into concepts. I didn't really understand attention blocks yet, and the way I think of concepts, is sorta like a vector, but I consider them differently (they have a n-dimensional position and a vibration/rotation associated with them) -- so it's a bit different. anyway, last night, again I felt prompted to watch [a talk he gave on transformers and attention](https://www.youtube.com/watch?v=KJtZARuO3JY), which totally connected all the dots for me. however, the main part about that kind of AI is that it gets trained on massive amounts of data -- and I just don't have an interface to be able to do something like that. what I mean is, the only input that [brb]

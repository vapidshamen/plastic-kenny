# ai-thinking

### 2025-11-19 23:10 - intro

I just watched another amazing [interview from dwarkesh with dario](https://youtu.be/Nlkk3glap_U). I had so many thoughts during the interview that it inspired me to want to pull out pytorch and start writing a small AI myself -- however, I feel some resistance to the idea (mostly because I just don't feel like I can code all of the heavy mathematics that are necessary for some of these ideas). so, instead -- I think it may be of more benefit to communicate my ideas in long-form and then just make entries here as I feel reactions to my thoughts and stuff. I have a lot to say, so this may be quite an active document for a little while. I first started talking about my AI ideas to talkie about a week ago (I think it was 11-11), but the AI was really not understanding me very well -- and I've had a lot of reactions to those thoughts since as well.
the advantage that I have is an incredible ability for self-introspection of my body, brain and mind (or consciousness, or whatever you want to call it). I actually subscribe to the same perspective that tesla has where my mind or consciousness does not live inside of my body, and that the body is a programmed reaction machine that is operating in the physical environment receiving signals (or "will") from my consciousness. so,	in broad form, we can think of the weights of the model and the platform it runs on to be similar to the automaton of the body. I feel like the LLMs are doing a great job of replicating and producing an even more powerful automaton (something that reacts to input/stimulus) than I'm able to do -- so I don't want to talk too much about that. the model can be considered like the neurons of the brain -- so because so many people understand the symbolic system that the concepts live in (ie, the neuronal structure) way better than I do, I would like to spend most of my time describing the consciousness or conceptual structure that causes these neurons to fire more than the structure itself.
to explain what I mean, I must now refer back to the 7-layer model of reality, and say that all 4 layers below structure (3) are contained within the structure. this is easy to see where the tokens (which can be thought of as the simplest form of a concept) which the models operate on, are just an array of vectors. obviously larger concepts have many more vectors, and the neurons that align with those concepts (ie, that "align" or are fired) when those concepts are evoked relate to the cOncept preceding it (or proceeding it if we look at a token in the middle of a text string). therefore, we can think of a string of text as a series of vectors over time -- which can then be thought of now as a curve (this goes for both input and output) -- so that when a model is using its structure to output a concept (5) as a series of tokens (or a series of tokens used to describe a concept) can be thought of as curves. the same goes for the other layers as well -- though I won't really talk about them too much in this document. the important thing to note is that concepts are theirselves derived from symbols/tokens and the symbols/tokens can be used to describe a cOncepet as well (in the same way that we have a particle/symbol wave/concept duality). the physical experience (7) (which for most models are just tokens) is also an extension of the symbolic as well, as we can decompose sound, touch, smell, light, etc into input waves as well (which then get translated into symbolic tokens that the model can then use).

### on security and introspection
### what is a concept
### thoughts on RL

rl is not synchronous -- as in, it one should be able to look at something in "hindsight", determine the concepts which arrived me to that conclusion, and begin to rearrange the concepts themselves and the relationships between them, to optimise for the feedback.
additionally, rl feedback is not binary or one-dimensional, but a concept itself which describes what worked and didn't work

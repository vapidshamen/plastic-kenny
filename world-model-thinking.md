# world-model-thinking

### 2025-11-26 00:56 - initial thoughts

so, I started listening to [another podcast right afterward](https://youtu.be/Ctjiatnd6Xk) with dr fei-fei li, and one of the things that she's talking about is world models. I find the whole subject fascinating, because for me a world model is a concept (I'll get tto more on that soon) -- and then she talks about how robots living in that world need to identify concepts in the world (an object/concept which is composed of many parts/concepts) -- and the properties of those objects/parts/concepts then can be used to generate action (like understanding that a door has hinges and that if the door can be separated from the hinges, someone/something on the other side can be extracted). that whole thing is quite an interesing tthing for me to think about (I really want to talk more about this idea).
anyway, she talked about their first product, "marble" -- a (language?) model that can generate 3d worlds based on descriptions and images. I opened it up, and tried out [my first world](https://marble.worldlabs.ai/world/b3f66222-246e-49e7-9775-cfac7680b188) -- a world with an ocean and a beach and some other things in it. one of the weird things was that I was completely unimpressed by it (oops!) -- and the first tthing I tried was to go under the water to see if it had a concept of what under the water near a beach looks like (it had a sort of blackness below and a blue surface above but it didn't continue the beach sand down under the water or continue the rocks of the cliff to be seen under the water). the next thing that I noticed was that there was a cave on the side of the cliff -- and as I approached it, it got pixelated (the opening didn't seem to generate depth) and when I tried to go inside of the cave, it didn't really have a cave-like interior to it (it was more like the edge of a map as if I were playing a fps).
so, the reason why I'm writing here is that it seems plainly obvious to me that the AI generating the world does not have a concept of what is under the water, in the bail of hay, or inside of the cave -- so that got me thinking: as I approach the threshold of these objects (ie, as soon as I go under water, inside of the haystack, or in the cave), I feel like there should be an automatic mode where the AI "imagines" what would be inside -- or perhaps in narrative mode, as soon as the AI is uncertain about what the next part of the world is like (what's inside of the haystack, in the cave, under the water, or behind the cliffs at the edge of the lagoon), the model should prompt the user/agent to describe what's there (or edit some pre-generated text of what it will imagine (same as in the auto mode)), and in this way, the user can go around customising the world in which they're experinecing. additionally, it would be pretty cool if any concept in the world could be outlined (with like a border around it) and then the user/agent could then edit the description of that concept/object -- allowing me to alter the personality or appearance of something I'm interacting with.
